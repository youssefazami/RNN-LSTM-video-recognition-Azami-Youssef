{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy9AGjQE0T2g"
      },
      "source": [
        "# Uploading Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "50RD9GepzbI4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIyKHJHq0bpT",
        "outputId": "3fec402e-669b-4e3e-c0a4-e2b303f909f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['body-building', 'boxing', 'calesthenics', 'cycling', 'swimming', 'yoga']\n"
          ]
        }
      ],
      "source": [
        "path = 'data'\n",
        "dataset_path = os.listdir( path)\n",
        "\n",
        "label_types = os.listdir( path)\n",
        "print (label_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mErh03Bn1n4H",
        "outputId": "60fd90e3-8350-477e-e372-5887a9def53d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             tag                 video_name\n",
            "0  body-building   data/body-building/1.mp4\n",
            "1  body-building  data/body-building/10.mp4\n",
            "2  body-building  data/body-building/11.mp4\n",
            "3  body-building  data/body-building/12.mp4\n",
            "4  body-building  data/body-building/13.mp4\n",
            "       tag                                         video_name\n",
            "1633  yoga  data/yoga/Young Healthy Girl Practicing Yoga B...\n",
            "1634  yoga  data/yoga/Young Pregnant Woman Doing Yoga Outd...\n",
            "1635  yoga  data/yoga/Young Woman Doing Balance Exercise S...\n",
            "1636  yoga  data/yoga/Young Woman Doing Meditation Exercis...\n",
            "1637  yoga  data/yoga/Young Woman Doing Yoga White Room St...\n"
          ]
        }
      ],
      "source": [
        "rooms = []\n",
        "\n",
        "for item in dataset_path:\n",
        " # Get all the file names\n",
        " all_rooms = os.listdir( path + '/' +item)\n",
        "\n",
        " # Add them to the list\n",
        " for room in all_rooms:\n",
        "    rooms.append((item, str( path + '/' +item) + '/' + room))\n",
        "\n",
        "# Build a dataframe\n",
        "data = pd.DataFrame( data=rooms, columns=['tag', 'video_name'])\n",
        "print(data.head())\n",
        "print(data.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dj7kiuJO4NVF"
      },
      "outputs": [],
      "source": [
        "df = data.loc[:,['video_name','tag']]\n",
        "df\n",
        "df.to_csv('fitness_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oec9oT214u-Q"
      },
      "source": [
        "# Preparing Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GZBu-zZm4wAe"
      },
      "outputs": [],
      "source": [
        "df = df.sample(frac = 1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data= train_test_split( data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "qqBsUpqL6Yev",
        "outputId": "c24d1abb-5f03-4591-e4af-7b94da64428c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='tag', ylabel='count'>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.countplot(x=train_data['tag'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "4TGfrOsa60LU",
        "outputId": "d0d156b8-b65d-4335-af0a-89ec0a4be550"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='tag', ylabel='count'>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(x=test_data['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6Sjuzx2a5SBV"
      },
      "outputs": [],
      "source": [
        "#!pip install git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4SA9Zdiz5dJm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_lD8WiQF5fI5"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "  except RuntimeError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i06yp0f5iCl"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "0wVrtVp28EBY",
        "outputId": "558da60d-13d0-4b3d-ff6c-e7935e2cc6c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total videos for training: 1310\n",
            "Total videos for testing: 328\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>yoga</td>\n",
              "      <td>data/yoga/Yoga Video Footage – Browse 197,616 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>boxing</td>\n",
              "      <td>data/boxing/Shadow boxing stock photos, royalt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>body-building</td>\n",
              "      <td>data/body-building/Leg press stock photos, roy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>body-building</td>\n",
              "      <td>data/body-building/Lateral raise stock photos,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>body-building</td>\n",
              "      <td>data/body-building/Cable flies exercise stock ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>body-building</td>\n",
              "      <td>data/body-building/58.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>boxing</td>\n",
              "      <td>data/boxing/Punching bag boxing stock photos, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1522</th>\n",
              "      <td>yoga</td>\n",
              "      <td>data/yoga/Yoga stock photos, royalty-free imag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>cycling</td>\n",
              "      <td>data/cycling/Cycling Video Footage – Browse 57...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>calesthenics</td>\n",
              "      <td>data/calesthenics/Squats stock photos, royalty...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                tag                                         video_name\n",
              "1598           yoga  data/yoga/Yoga Video Footage – Browse 197,616 ...\n",
              "448          boxing  data/boxing/Shadow boxing stock photos, royalt...\n",
              "224   body-building  data/body-building/Leg press stock photos, roy...\n",
              "188   body-building  data/body-building/Lateral raise stock photos,...\n",
              "110   body-building  data/body-building/Cable flies exercise stock ...\n",
              "52    body-building                          data/body-building/58.mp4\n",
              "355          boxing  data/boxing/Punching bag boxing stock photos, ...\n",
              "1522           yoga  data/yoga/Yoga stock photos, royalty-free imag...\n",
              "1004        cycling  data/cycling/Cycling Video Footage – Browse 57...\n",
              "849    calesthenics  data/calesthenics/Squats stock photos, royalty..."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f\"Total videos for training: {len( train_data)}\")\n",
        "print(f\"Total videos for testing: {len(test_data)}\")\n",
        "\n",
        "\n",
        "train_data.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pNkyRju8XVO"
      },
      "source": [
        "# Preprocessing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zUZxg7ww8XBk"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 360\n",
        "\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9vUM81s8nTO"
      },
      "source": [
        "* Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FowCdKyt8qMh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    )\n",
        "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "\n",
        "feature_extractor = build_feature_extractor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-oeaoB58vbF"
      },
      "source": [
        "* Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l236Wr_b8xpo",
        "outputId": "00c5d570-930d-4238-ec6b-ab600898e0e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['body-building', 'boxing', 'calesthenics', 'cycling', 'swimming', 'yoga']\n",
            "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [4],\n",
              "       [3],\n",
              "       ...,\n",
              "       [2],\n",
              "       [5],\n",
              "       [4]], dtype=int64)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique( train_data[ 'tag']))\n",
        "print( label_processor.get_vocabulary())\n",
        "\n",
        "labels = train_data[ 'tag'].values\n",
        "labels = label_processor( labels[..., None]).numpy()\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FKCigsAD9Sy3"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 360\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4JUw0379YXe",
        "outputId": "3ea7f7af-61da-416f-85c5-7fe1fb38846e"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[1;32mc:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\aminb\\Downloads\\RNN\\Video_Exercices_Classification.ipynb Cell 22\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aminb/Downloads/RNN/Video_Exercices_Classification.ipynb#X30sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m train_data, train_labels \u001b[39m=\u001b[39m prepare_all_videos( train_data, path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aminb/Downloads/RNN/Video_Exercices_Classification.ipynb#X30sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m test_data, test_labels \u001b[39m=\u001b[39m prepare_all_videos( test_data, path)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aminb/Downloads/RNN/Video_Exercices_Classification.ipynb#X30sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFrame features in train set: \u001b[39m\u001b[39m{\u001b[39;00mdata[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aminb/Downloads/RNN/Video_Exercices_Classification.ipynb#X30sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFrame masks in train set: \u001b[39m\u001b[39m{\u001b[39;00mdata[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aminb/Downloads/RNN/Video_Exercices_Classification.ipynb#X30sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain_labels in train set: \u001b[39m\u001b[39m{\u001b[39;00mtrain_labels\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
            "File \u001b[1;32mc:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 0"
          ]
        }
      ],
      "source": [
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"video_name\"].values.tolist()\n",
        "\n",
        "    ##take all classlabels from train_df column named 'tag' and store in labels\n",
        "    labels = df[\"tag\"].values\n",
        "\n",
        "    #convert classlabels to label encoding\n",
        "    labels = label_processor(labels[..., None]).numpy()\n",
        "\n",
        "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
        "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
        "    # masked with padding or not.\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\") # 145,20\n",
        "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\") #145,20,2048\n",
        "\n",
        "    # For each video.\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        print( idx)\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        frames = load_video(os.path.join(root_dir, path))\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "        # Initialize placeholders to store the masks and features of the current video.\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(\n",
        "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
        "                    batch[None, j, :]\n",
        "                )\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels\n",
        "\n",
        "\n",
        "train_data, train_labels = prepare_all_videos( train_data, path)\n",
        "test_data, test_labels = prepare_all_videos( test_data, path)\n",
        "\n",
        "print(f\"Frame features in train set: {data[0].shape}\")\n",
        "print(f\"Frame masks in train set: {data[1].shape}\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"train_labels in train set: {train_labels.shape}\")\n",
        "\n",
        "print(f\"test_labels in train set: {test_labels.shape}\")\n",
        "\n",
        "# MAX_SEQ_LENGTH = 20, NUM_FEATURES = 2048. We have defined this above under hyper parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxJG6SH8AMwz"
      },
      "source": [
        "# The sequence model\n",
        "Now, we can feed this data to a sequence model consisting of recurrent layers like GRU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ETuz1vceAPt9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7919 - accuracy: 0.1518\n",
            "Epoch 1: val_loss improved from inf to 1.79165, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 12s 124ms/step - loss: 1.7919 - accuracy: 0.1507 - val_loss: 1.7917 - val_accuracy: 0.1726\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7916 - accuracy: 0.1845\n",
            "Epoch 2: val_loss improved from 1.79165 to 1.79149, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.7916 - accuracy: 0.1845 - val_loss: 1.7915 - val_accuracy: 0.1675\n",
            "Epoch 3/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7914 - accuracy: 0.1852\n",
            "Epoch 3: val_loss improved from 1.79149 to 1.79147, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.7914 - accuracy: 0.1845 - val_loss: 1.7915 - val_accuracy: 0.1675\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7913 - accuracy: 0.1845\n",
            "Epoch 4: val_loss improved from 1.79147 to 1.79139, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.7913 - accuracy: 0.1845 - val_loss: 1.7914 - val_accuracy: 0.1675\n",
            "Epoch 5/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7911 - accuracy: 0.1864\n",
            "Epoch 5: val_loss improved from 1.79139 to 1.79126, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.7911 - accuracy: 0.1845 - val_loss: 1.7913 - val_accuracy: 0.1675\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7910 - accuracy: 0.1845\n",
            "Epoch 6: val_loss improved from 1.79126 to 1.79123, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7910 - accuracy: 0.1845 - val_loss: 1.7912 - val_accuracy: 0.1675\n",
            "Epoch 7/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7909 - accuracy: 0.1815\n",
            "Epoch 7: val_loss improved from 1.79123 to 1.79116, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7909 - accuracy: 0.1845 - val_loss: 1.7912 - val_accuracy: 0.1675\n",
            "Epoch 8/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7909 - accuracy: 0.1838\n",
            "Epoch 8: val_loss improved from 1.79116 to 1.79113, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7908 - accuracy: 0.1845 - val_loss: 1.7911 - val_accuracy: 0.1675\n",
            "Epoch 9/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7912 - accuracy: 0.1813\n",
            "Epoch 9: val_loss improved from 1.79113 to 1.79104, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7908 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7907 - accuracy: 0.1845\n",
            "Epoch 10: val_loss did not improve from 1.79104\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7907 - accuracy: 0.1845 - val_loss: 1.7911 - val_accuracy: 0.1675\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7906 - accuracy: 0.1845\n",
            "Epoch 11: val_loss improved from 1.79104 to 1.79102, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 1.7906 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 12/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7908 - accuracy: 0.1840\n",
            "Epoch 12: val_loss improved from 1.79102 to 1.79075, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7906 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 13/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7903 - accuracy: 0.1864\n",
            "Epoch 13: val_loss did not improve from 1.79075\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7905 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7905 - accuracy: 0.1845\n",
            "Epoch 14: val_loss did not improve from 1.79075\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7905 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 15/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7904 - accuracy: 0.1815\n",
            "Epoch 15: val_loss improved from 1.79075 to 1.79069, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7904 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7904 - accuracy: 0.1845\n",
            "Epoch 16: val_loss did not improve from 1.79069\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 1.7904 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 17/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7900 - accuracy: 0.1851\n",
            "Epoch 17: val_loss did not improve from 1.79069\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7905 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7904 - accuracy: 0.1845\n",
            "Epoch 18: val_loss did not improve from 1.79069\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.7904 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 19/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7900 - accuracy: 0.1838\n",
            "Epoch 19: val_loss did not improve from 1.79069\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 1.7904 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7904 - accuracy: 0.1845\n",
            "Epoch 20: val_loss did not improve from 1.79069\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 1.7904 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 21/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7903 - accuracy: 0.1838\n",
            "Epoch 21: val_loss did not improve from 1.79069\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 22/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 1.7903 - accuracy: 0.1836\n",
            "Epoch 22: val_loss did not improve from 1.79069\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 23/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7909 - accuracy: 0.1767\n",
            "Epoch 23: val_loss did not improve from 1.79069\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 1.7904 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 24/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7910 - accuracy: 0.1750\n",
            "Epoch 24: val_loss did not improve from 1.79069\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 25/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7902 - accuracy: 0.1853\n",
            "Epoch 25: val_loss did not improve from 1.79069\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 26/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7904 - accuracy: 0.1829\n",
            "Epoch 26: val_loss did not improve from 1.79069\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 27/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7902 - accuracy: 0.1827\n",
            "Epoch 27: val_loss improved from 1.79069 to 1.79064, saving model to ./tmp\\video_classifier\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7906 - val_accuracy: 0.1675\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7903 - accuracy: 0.1845\n",
            "Epoch 28: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 29/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7900 - accuracy: 0.1840\n",
            "Epoch 29: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 30/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7904 - accuracy: 0.1840\n",
            "Epoch 30: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 31/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7904 - accuracy: 0.1863\n",
            "Epoch 31: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 32/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7901 - accuracy: 0.1875\n",
            "Epoch 32: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7903 - accuracy: 0.1845\n",
            "Epoch 33: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 34/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7901 - accuracy: 0.1853\n",
            "Epoch 34: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7902 - accuracy: 0.1845\n",
            "Epoch 35: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 36/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7900 - accuracy: 0.1853\n",
            "Epoch 36: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7903 - accuracy: 0.1845\n",
            "Epoch 37: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 38/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7911 - accuracy: 0.1803\n",
            "Epoch 38: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 1s 17ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 39/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7899 - accuracy: 0.1839\n",
            "Epoch 39: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 40/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7912 - accuracy: 0.1779\n",
            "Epoch 40: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7902 - accuracy: 0.1845\n",
            "Epoch 41: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7903 - accuracy: 0.1845\n",
            "Epoch 42: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 43/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7898 - accuracy: 0.1850\n",
            "Epoch 43: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 44/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7889 - accuracy: 0.1937\n",
            "Epoch 44: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7903 - accuracy: 0.1845\n",
            "Epoch 45: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 46/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7902 - accuracy: 0.1864\n",
            "Epoch 46: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 47/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7907 - accuracy: 0.1817\n",
            "Epoch 47: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7903 - accuracy: 0.1845\n",
            "Epoch 48: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 49/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7904 - accuracy: 0.1825\n",
            "Epoch 49: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 50/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7905 - accuracy: 0.1815\n",
            "Epoch 50: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7903 - accuracy: 0.1845\n",
            "Epoch 51: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 52/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7899 - accuracy: 0.1875\n",
            "Epoch 52: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 53/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7903 - accuracy: 0.1853\n",
            "Epoch 53: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7902 - accuracy: 0.1845\n",
            "Epoch 54: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 55/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7901 - accuracy: 0.1853\n",
            "Epoch 55: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7903 - accuracy: 0.1845\n",
            "Epoch 56: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 57/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7899 - accuracy: 0.1875\n",
            "Epoch 57: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 58/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7915 - accuracy: 0.1787\n",
            "Epoch 58: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 59/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7902 - accuracy: 0.1864\n",
            "Epoch 59: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 60/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7901 - accuracy: 0.1875\n",
            "Epoch 60: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 61/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7909 - accuracy: 0.1782\n",
            "Epoch 61: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 62/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7901 - accuracy: 0.1840\n",
            "Epoch 62: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 63/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7902 - accuracy: 0.1842\n",
            "Epoch 63: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7903 - accuracy: 0.1845\n",
            "Epoch 64: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 65/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7903 - accuracy: 0.1830\n",
            "Epoch 65: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 66/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7910 - accuracy: 0.1819\n",
            "Epoch 66: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7904 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 67/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7905 - accuracy: 0.1830\n",
            "Epoch 67: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 68/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7900 - accuracy: 0.1842\n",
            "Epoch 68: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 69/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7905 - accuracy: 0.1808\n",
            "Epoch 69: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 70/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7905 - accuracy: 0.1830\n",
            "Epoch 70: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7902 - accuracy: 0.1845\n",
            "Epoch 71: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 72/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 1.7898 - accuracy: 0.1849\n",
            "Epoch 72: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 73/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 1.7900 - accuracy: 0.1862\n",
            "Epoch 73: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7904 - accuracy: 0.1845\n",
            "Epoch 74: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7904 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 75/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7899 - accuracy: 0.1853\n",
            "Epoch 75: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7902 - accuracy: 0.1845\n",
            "Epoch 76: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 77/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7904 - accuracy: 0.1803\n",
            "Epoch 77: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 78/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7908 - accuracy: 0.1791\n",
            "Epoch 78: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 79/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7901 - accuracy: 0.1852\n",
            "Epoch 79: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7902 - accuracy: 0.1845\n",
            "Epoch 80: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7902 - accuracy: 0.1845\n",
            "Epoch 81: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 82/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7916 - accuracy: 0.1779\n",
            "Epoch 82: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 83/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7903 - accuracy: 0.1825\n",
            "Epoch 83: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 84/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7909 - accuracy: 0.1825\n",
            "Epoch 84: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7911 - val_accuracy: 0.1675\n",
            "Epoch 85/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7900 - accuracy: 0.1863\n",
            "Epoch 85: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 86/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7908 - accuracy: 0.1815\n",
            "Epoch 86: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.7902 - accuracy: 0.1845\n",
            "Epoch 87: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 88/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 1.7897 - accuracy: 0.1862\n",
            "Epoch 88: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7910 - val_accuracy: 0.1675\n",
            "Epoch 89/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7911 - accuracy: 0.1806\n",
            "Epoch 89: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7911 - val_accuracy: 0.1675\n",
            "Epoch 90/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7901 - accuracy: 0.1887\n",
            "Epoch 90: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7911 - val_accuracy: 0.1675\n",
            "Epoch 91/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7907 - accuracy: 0.1817\n",
            "Epoch 91: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 92/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 1.7902 - accuracy: 0.1840\n",
            "Epoch 92: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 93/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 1.7897 - accuracy: 0.1863\n",
            "Epoch 93: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 94/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7904 - accuracy: 0.1842\n",
            "Epoch 94: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 95/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7908 - accuracy: 0.1830\n",
            "Epoch 95: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 96/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7904 - accuracy: 0.1863\n",
            "Epoch 96: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7909 - val_accuracy: 0.1675\n",
            "Epoch 97/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7903 - accuracy: 0.1853\n",
            "Epoch 97: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 98/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 1.7903 - accuracy: 0.1827\n",
            "Epoch 98: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7903 - accuracy: 0.1845 - val_loss: 1.7907 - val_accuracy: 0.1675\n",
            "Epoch 99/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7902 - accuracy: 0.1830\n",
            "Epoch 99: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "Epoch 100/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.7906 - accuracy: 0.1819\n",
            "Epoch 100: val_loss did not improve from 1.79064\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.7902 - accuracy: 0.1845 - val_loss: 1.7908 - val_accuracy: 0.1675\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.7848 - accuracy: 0.2348\n",
            "Test accuracy: 23.48%\n"
          ]
        }
      ],
      "source": [
        "# Utility for our sequence model.\n",
        "def get_sequence_model():\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
        "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
        "    x = keras.layers.LSTM(16, return_sequences=True, stateful=False)(frame_features_input, mask=mask_input)\n",
        "    x = keras.layers.LSTM(8, stateful=False)(x)\n",
        "    x = keras.layers.Dropout(0.4)(x)\n",
        "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
        "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
        "\n",
        "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "    rnn_model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return rnn_model\n",
        "\n",
        "\n",
        "# Utility for running experiments.\n",
        "def run_experiment():\n",
        "    filepath = \"./tmp/video_classifier\"\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
        "    )\n",
        "\n",
        "    seq_model = get_sequence_model()\n",
        "    history = seq_model.fit(\n",
        "        [train_data[0], train_data[1]],\n",
        "        train_labels,\n",
        "        validation_split=0.3,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[checkpoint],\n",
        "    )\n",
        "\n",
        "    seq_model.load_weights(filepath)\n",
        "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, seq_model\n",
        "\n",
        "\n",
        "_, sequence_model = run_experiment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuEQufYUA4IR"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ6cUM4ZA5ZZ"
      },
      "outputs": [],
      "source": [
        "def prepare_single_video(frames):\n",
        "    frames = frames[None, ...]\n",
        "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    for i, batch in enumerate(frames):\n",
        "        video_length = batch.shape[0]\n",
        "        length = min(MAX_SEQ_LENGTH, video_length)\n",
        "        for j in range(length):\n",
        "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
        "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "    return frame_features, frame_mask\n",
        "\n",
        "\n",
        "def sequence_prediction(path_):\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frames = load_video(os.path.join( path, path_))\n",
        "    frame_features, frame_mask = prepare_single_video(frames)\n",
        "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
        "\n",
        "    for i in np.argsort(probabilities)[::-1]:\n",
        "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
        "    return frames\n",
        "\n",
        "test_video = np.random.choice( test_data[\"video_name\"].values.tolist())\n",
        "print(f\"Test video path: {test_video}\")\n",
        "\n",
        "test_frames = sequence_prediction(test_video)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUZHE_ZjA7v1"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"\n",
        "    <video alt=\"test\" width=\"520\" height=\"440\" controls>\n",
        "        <source src=\"\" type=\"video/mp4\" style=\"height:300px;width:300px\">\n",
        "    </video>\n",
        "\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
