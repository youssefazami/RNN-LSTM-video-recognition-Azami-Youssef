{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 512\n",
    "\n",
    "class_vocab = ['body-building', 'boxing', 'calesthenics', 'cycling', 'swimming', 'yoga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 25 variables. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def get_sequence_model():\n",
    "    frame_features_input = keras.Input(( MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input(( MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    x = keras.layers.LSTM( 64, return_sequences=True, stateful=False)(frame_features_input, mask=mask_input)\n",
    "    x = keras.layers.LSTM( 16, return_sequences=True, stateful=False)( x)\n",
    "    x = keras.layers.Flatten()( x)\n",
    "    x = keras.layers.BatchNormalization()( x)\n",
    "    x = keras.layers.Dropout( 0.5)(x)\n",
    "    x = keras.layers.Dense( 8, activation=\"relu\")(x)\n",
    "    \n",
    "    output = keras.layers.Dense( len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer= tf.keras.optimizers.Adam(), metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "sequence_model = get_sequence_model()\n",
    "sequence_model.load_weights( 'models/best_model_29_11.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\aminb\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3, VGG16\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "def build_feature_extractor(model_name=\"inception_v3\"):\n",
    "    if model_name == \"inception_v3\":\n",
    "        feature_extractor = InceptionV3(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,\n",
    "            pooling=\"avg\",\n",
    "            input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        )\n",
    "        preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "    elif model_name == \"vgg16\":\n",
    "        feature_extractor = VGG16(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,\n",
    "            pooling=\"avg\",\n",
    "            input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        )\n",
    "        preprocess_input = keras.applications.vgg16.preprocess_input\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name. Supported names: 'inception_v3', 'vgg16'\")\n",
    "\n",
    "    inputs = Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return Model(inputs, outputs, name=f\"{model_name}_feature_extractor\")\n",
    "\n",
    "# To use InceptionV3\n",
    "inception_feature_extractor = build_feature_extractor(model_name=\"inception_v3\")\n",
    "\n",
    "# To use VGG16\n",
    "vgg16_feature_extractor = build_feature_extractor(model_name=\"vgg16\")\n",
    "\n",
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = vgg16_feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "import os\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['body-building', 'boxing', 'calesthenics', 'cycling', 'swimming', 'yoga']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'C:/Users/aminb/Downloads/RNN/data'\n",
    "dataset_path = os.listdir( path)\n",
    "\n",
    "label_types = os.listdir( path)\n",
    "print (label_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tag                                         video_name\n",
      "0  body-building  C:/Users/aminb/Downloads/RNN/data/body-buildin...\n",
      "1  body-building  C:/Users/aminb/Downloads/RNN/data/body-buildin...\n",
      "2  body-building  C:/Users/aminb/Downloads/RNN/data/body-buildin...\n",
      "3  body-building  C:/Users/aminb/Downloads/RNN/data/body-buildin...\n",
      "4  body-building  C:/Users/aminb/Downloads/RNN/data/body-buildin...\n",
      "       tag                                         video_name\n",
      "1633  yoga  C:/Users/aminb/Downloads/RNN/data/yoga/Young H...\n",
      "1634  yoga  C:/Users/aminb/Downloads/RNN/data/yoga/Young P...\n",
      "1635  yoga  C:/Users/aminb/Downloads/RNN/data/yoga/Young W...\n",
      "1636  yoga  C:/Users/aminb/Downloads/RNN/data/yoga/Young W...\n",
      "1637  yoga  C:/Users/aminb/Downloads/RNN/data/yoga/Young W...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rooms = []\n",
    "\n",
    "for item in dataset_path:\n",
    " # Get all the file names\n",
    " all_rooms = os.listdir( path + '/' +item)\n",
    "\n",
    " # Add them to the list\n",
    " for room in all_rooms:\n",
    "    rooms.append((item, str( path + '/' +item) + '/' + room))\n",
    "\n",
    "# Build a dataframe\n",
    "data = pd.DataFrame( data=rooms, columns=['tag', 'video_name'])\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: C:/Users/aminb/Downloads/RNN/data/cycling/Cycling stock photos, royalty-free images, vectors, video_63.mp4\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 1s 500ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "  cycling: 81.23%\n",
      "  swimming: 15.34%\n",
      "  calesthenics:  1.58%\n",
      "  body-building:  0.95%\n",
      "  boxing:  0.77%\n",
      "  yoga:  0.13%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_video = np.random.choice( data[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction( test_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt='test' width='520' height='440' controls><source src='data/cycling/Cycling stock photos, royalty-free images, vectors, video_63.mp4' type='video/mp4' style='height:300px;width:300px'></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "html = \"<video alt='test' width='520' height='440' controls><source src='\" + test_video[29:] + \"' type='video/mp4' style='height:300px;width:300px'></video>\"\n",
    "\n",
    "HTML( html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
